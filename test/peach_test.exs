defmodule PeachTest do
  # import CSVLixir
  use ExUnit.Case
  doctest Peach

  @tag timeout: 6_000_000
  test "normalise_text" do
    test_data = [
      ["foo", "foo"],
      ["\n", "\n"],
      ["ðŸš¼", "ðŸš¼"],
      [[500], "Ç´"],
      [[600], "É˜"],
      ["ï¼‹ï¼ï¼Žï½žï¼‰ï½", "+-.~)}"],
      ["ï¼‘ï¼’ï¼“", "123"],
      ["ï½ï½‚ï½ƒï¼¡ï¼¢ï¼£", "abcABC"]
    ]

    # Try to load alternative testing data.
    # CSVLixir requires the use if a try catch :-(
    test_data =
      try do
        Path.join(["test", "function_test_data", "normalise_text.csv"])
        |> Path.expand()
        |> CSVLixir.read()
        |> Enum.to_list()
      catch
        _kind, %File.Error{reason: :enoent} -> test_data |> Enum.to_list()
      end

    test_data
    |> Enum.map(fn [input, expected_output] ->
      assert Peach.normalise_text(input) == expected_output
    end)
  end

  @tag timeout: 6_000_000
  test "remove_emojis" do
    test_data = [
      ["ðŸ§ðŸ™ðŸ¾â€â™‚ï¸ðŸ¦ŽðŸ‡§ðŸ‡®ðŸ‡¦ðŸ‡¶", ""],
      ["ðŸ’”fooðŸˆ¶barâ®", "foobar"]
    ]

    # Try to load alternative testing data.
    # CSVLixir requires the use if a try catch :-(
    test_data =
      try do
        Path.join(["test", "function_test_data", "remove_emojis.csv"])
        |> Path.expand()
        |> CSVLixir.read()
        |> Enum.to_list()
      catch
        _kind, %File.Error{reason: :enoent} -> test_data |> Enum.to_list()
      end

    test_data
    |> Enum.map(fn [input, expected_output] ->
      Peach.remove_emojis(input) == expected_output
    end)
  end

  # there are some failing cases in the emoji removal
  # this test is purely to document those cases
  test "document failing emoji removal" do
    assert Peach.remove_emojis("0ï¸âƒ£") != ""
    assert Peach.remove_emojis("1ï¸âƒ£") != ""
    assert Peach.remove_emojis("2ï¸âƒ£") != ""
    assert Peach.remove_emojis("3ï¸âƒ£") != ""
    assert Peach.remove_emojis("4ï¸âƒ£") != ""
    assert Peach.remove_emojis("5ï¸âƒ£") != ""
    assert Peach.remove_emojis("6ï¸âƒ£") != ""
    assert Peach.remove_emojis("7ï¸âƒ£") != ""
    assert Peach.remove_emojis("8ï¸âƒ£") != ""
    assert Peach.remove_emojis("9ï¸âƒ£") != ""
    assert Peach.remove_emojis("#ï¸âƒ£") != ""
    assert Peach.remove_emojis("*ï¸âƒ£") != ""
    assert Peach.remove_emojis("Â©ï¸") != ""
    assert Peach.remove_emojis("Â®ï¸") != ""
  end

  @tag timeout: 6_000_000
  test "normalise_whitespace" do
    test_data = [
      ["in     put", "in put"],
      ["  ", ""],
      ["in     put ", "in put"]
    ]

    # Try to load alternative testing data.
    # CSVLixir requires the use if a try catch :-(
    test_data =
      try do
        Path.join(["test", "function_test_data", "normalise_whitespace.csv"])
        |> Path.expand()
        |> CSVLixir.read()
        |> Enum.to_list()
      catch
        _kind, %File.Error{reason: :enoent} -> test_data |> Enum.to_list()
      end

    test_data
    |> Enum.map(fn [input, expected_output] ->
      assert Peach.normalise_whitespace(input) == expected_output
    end)
  end

  @tag timeout: 6_000_000
  test "remove_punc" do
    test_data = [
      ["!@#$%^&*()", ""],
      [" ", " "]
    ]

    # Try to load alternative testing data.
    # CSVLixir requires the use if a try catch :-(
    test_data =
      try do
        Path.join(["test", "function_test_data", "remove_punc.csv"])
        |> Path.expand()
        |> CSVLixir.read()
        |> Enum.to_list()
      catch
        _kind, %File.Error{reason: :enoent} -> test_data |> Enum.to_list()
      end

    test_data
    |> Enum.map(fn [input, expected_output] ->
      assert Peach.remove_punc(input) == expected_output
    end)
  end

  @tag timeout: 6_000_000
  test "replace_punc" do
    test_data = [
      ["this.is.a.test", "this is a test"],
      ["!@#$%^&*()", String.duplicate(" ", 10)]
    ]

    # Try to load alternative testing data.
    # CSVLixir requires the use if a try catch :-(
    test_data =
      try do
        Path.join(["test", "function_test_data", "replace_punc.csv"])
        |> Path.expand()
        |> CSVLixir.read()
        |> Enum.to_list()
      catch
        _kind, %File.Error{reason: :enoent} -> test_data |> Enum.to_list()
      end

    test_data
    |> Enum.map(fn [input, expected_output] ->
      assert Peach.replace_punc(input) == expected_output
    end)
  end

  @tag timeout: 6_000_000
  test "remove_numbers" do
    test_data = [
      ["1234", ""],
      ["1foo2", "foo2"],
      ["1 2 3 bar", "bar"]
    ]

    # Try to load alternative testing data.
    # CSVLixir requires the use if a try catch :-(
    test_data =
      try do
        Path.join(["test", "function_test_data", "remove_numbers.csv"])
        |> Path.expand()
        |> CSVLixir.read()
        |> Enum.to_list()
      catch
        _kind, %File.Error{reason: :enoent} -> test_data |> Enum.to_list()
      end

    test_data
    |> Enum.map(fn [input, expected_output] ->
      assert Peach.remove_numbers(input) == expected_output
    end)
  end

  @tag timeout: 6_000_000
  test "pre_process" do
    test_data = [
      # ["Ø§","Ø§"], FAILURE CASE
      # ["Ù…Ø§ÙÙ‡Ù…Øª","Ù…Ø§ÙÙ‡Ù…Øª"], FAILURE CASE
      ["Travel advice", "travel advice"],
      ["Hi", "hi"],
      ["2ï¸âƒ£", "2"],
      ["1ï¸âƒ£", "1"]
    ]

    # Try to load alternative testing data.
    # CSVLixir requires the use if a try catch :-(
    test_data =
      try do
        Path.join(["test", "function_test_data", "pre_process.csv"])
        |> Path.expand()
        |> CSVLixir.read()
        |> Enum.to_list()
      catch
        _kind, %File.Error{reason: :enoent} -> test_data |> Enum.to_list()
      end

    test_data
    |> Enum.map(fn [input, expected_output] ->
      assert Peach.pre_process(input) == expected_output
    end)
  end

  test "convert to one line" do
    test_data = [
      ["\nfoo\nbar", "\\nfoo\\nbar"],
      ["\rfoo\rbar", "\\rfoo\\rbar"]
    ]

    test_data
    |> Enum.map(fn [input, expected_output] ->
      assert Peach.convert_to_one_line(input) == expected_output
    end)
  end

  test "levenshtein" do
    assert Peach.levenshtein_distance("foo", "bar") == 3
    assert Peach.levenshtein_distance("foo", "bar") != 2
    assert Peach.levenshtein_distance("", "") == 0
    assert Peach.levenshtein_distance("foo", "") == 3
  end

  test "ex_find_exact_match" do
    test_data = [
      ["*menu*", MapSet.new(["menu", "opt-in", "opt-out"]), "menu"],
      ["2.", MapSet.new(["1", "2", "3"]), "2"]
    ]

    test_data_neg = [
      ["*home*", MapSet.new(["menu", "opt-in", "opt-out"]), "menu"],
      ["4.", MapSet.new(["1", "2", "3"]), "2"]
    ]

    test_data
    |> Enum.map(fn [input, keywords, expected_match] ->
      assert expected_match ==
               Peach.pre_process(input)
               |> Peach.find_exact_match(keywords)
    end)

    test_data_neg
    |> Enum.map(fn [input, keywords, _expected_match] ->
      assert nil ==
               Peach.pre_process(input)
               |> Peach.find_exact_match(keywords)
    end)
  end

  test "find_fuzzy_matches_single_threshold" do
    keyword_set = MapSet.new(["menu", "optin", "optout"])

    test_data = [
      # one addition
      ["menuu", keyword_set, [{"menu", 1}]],
      # one deletion
      ["opin", keyword_set, [{"optin", 1}]],
      # exact match
      ["optin", keyword_set, [{"optin", 0}]],
      # exact match
      ["optout", keyword_set, [{"optout", 0}]],
      # one addition
      ["optint", keyword_set, [{"optin", 1}]]
    ]

    threshold = 1

    test_data
    |> Enum.map(fn [input, keyword_set, expected_matches] ->
      assert expected_matches ==
               Peach.pre_process(input)
               |> Peach.find_fuzzy_matches(keyword_set, threshold)
    end)
  end

  test "find_fuzzy_matches" do
    keyword_threshold_set = MapSet.new([{"menu", 1}, {"optin", 2}, {"optout", 2}])

    test_data = [
      # one addition
      ["menuu", keyword_threshold_set, [{"menu", 1}]],
      # one deletion
      ["opin", keyword_threshold_set, [{"optin", 1}]],
      # exact match
      ["optin", keyword_threshold_set, [{"optin", 0}]],
      # exact match
      ["optout", keyword_threshold_set, [{"optout", 0}]],
      # one addition, two replacements
      ["optint", keyword_threshold_set, [{"optin", 1}, {"optout", 2}]]
    ]

    test_data
    |> Enum.map(fn [input, keyword_threshold_set, expected_matches] ->
      assert expected_matches ==
               Peach.pre_process(input)
               |> Peach.find_fuzzy_matches(keyword_threshold_set)
    end)
  end

  test "general_use_cases" do
    # Menu number and exact keyword match.
    input = "2.)"
    keyword_set = MapSet.new(["1", "2", "menu"])

    matches =
      Peach.pre_process(input)
      |> Peach.find_exact_match(keyword_set)

    assert matches == "2"

    input = "_menu_"
    keyword_set = MapSet.new(["1", "2", "menu"])

    matches =
      Peach.pre_process(input)
      |> Peach.find_exact_match(keyword_set)

    assert matches == "menu"

    # Fuzzy keyword match with global threshold.
    input = "menuu"
    keyword_set = MapSet.new(["menu", "optin", "optout"])
    threshold = 1

    matches =
      Peach.pre_process(input)
      |> Peach.find_fuzzy_matches(keyword_set, threshold)

    assert matches == [{"menu", 1}]

    # Fuzzy keyword match with a threshold per keyword.
    input = "optint"
    keyword_threshold_set = MapSet.new([{"menu", 1}, {"optin", 2}, {"optout", 2}])

    matches =
      Peach.pre_process(input)
      |> Peach.find_fuzzy_matches(keyword_threshold_set)

    assert matches == [{"optin", 1}, {"optout", 2}]

    input = "202001"
    keyword_threshold_set = MapSet.new([{"hi", 2}, {"aa", 2}, {"bb", 2}, {"foo", 2}])

    matches =
      Peach.pre_process(input)
      |> Peach.find_fuzzy_matches(keyword_threshold_set)

    assert matches == []

    input = "202a001"
    keyword_threshold_set = MapSet.new([{"hi", 2}])

    matches =
      Peach.pre_process(input)
      |> Peach.find_fuzzy_matches(keyword_threshold_set)

    assert matches == []

    input = "202aa001"
    keyword_threshold_set = MapSet.new([{"hi", 2}])

    matches =
      Peach.pre_process(input)
      |> Peach.find_fuzzy_matches(keyword_threshold_set)

    assert matches == []
  end
end
